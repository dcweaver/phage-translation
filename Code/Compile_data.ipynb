{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gff3_parsing\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_genome(dataframe, energy_dict, gaps = (4,10), expected_len = 20):\n",
    "    \"\"\"\n",
    "    NEED DOCS\n",
    "    \"\"\"\n",
    "    for index in dataframe.index:\n",
    "        upstream = dataframe.loc[index,\"upstream_sequence\"]\n",
    "        test_string = upstream.replace(\"T\", \"U\")\n",
    "        if len(test_string) != expected_len:\n",
    "            continue\n",
    "        if test_string.count(\"A\") + test_string.count(\"U\") +\\\n",
    "                                    test_string.count(\"C\") + test_string.count(\"G\") != expected_len:\n",
    "            continue\n",
    "            \n",
    "        energy_list = []\n",
    "        for gap in range(gaps[0],gaps[1]+1):\n",
    "             energy_list.append(energy_dict[test_string[-gap - 6: -gap]])\n",
    "\n",
    "        dataframe.at[index, \"energy_binding\"] = min(energy_list)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"\\t\"\n",
    "upstream_len = 20\n",
    "\n",
    "with open('../Data/energy_files/energyRef_CCUCCU_ensemble_noneConstraint.json', 'r') as infile:\n",
    "       energy_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating initial host tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_ids = [36809,\\\n",
    "           717959,\\\n",
    "           305,\\\n",
    "           1590,\\\n",
    "           435591,\\\n",
    "           90371,\\\n",
    "           1314,\\\n",
    "           357276,\\\n",
    "           657318,\\\n",
    "           1639,\\\n",
    "           1428,\\\n",
    "           470,\\\n",
    "           573,\\\n",
    "           1280,\\\n",
    "           287,\\\n",
    "           562]\n",
    "\n",
    "for host_id in host_ids:\n",
    "    host_df, host_genome = gff3_parsing.compile_sequences([\"../Data/host_genomes/{}.gff3\".format(host_id)],\n",
    "                                                        [\"../Data/host_genomes/{}.fasta\".format(host_id)], upstream_len)\n",
    "    host_df = analyze_genome(host_df, energy_dict)\n",
    "    host_df.to_csv(\"../Data/host_genomes/{}.tsv\".format(host_id), sep = sep )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This one is an annoying 2 chromosome case\n",
    "host_id = 28450\n",
    "\n",
    "gffs = [\"../Data/host_genomes/{}.1.gff3\".format(host_id),\\\n",
    "        \"../Data/host_genomes/{}.2.gff3\".format(host_id)]\n",
    "\n",
    "fastas = [\"../Data/host_genomes/{}.1.fasta\".format(host_id),\\\n",
    "          \"../Data/host_genomes/{}.2.fasta\".format(host_id)]\n",
    "\n",
    "host_df, host_genome = gff3_parsing.compile_sequences(gffs, fastas, upstream_len)\n",
    "#combined_id = 28450\n",
    "host_df = analyze_genome(host_df, energy_dict)\n",
    "host_df.to_csv(\"../Data/host_genomes/{}.tsv\".format(host_id), sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating initial viral tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_host_ids = host_ids + [28450]\n",
    "\n",
    "for host_id in new_host_ids:\n",
    "    for gff_file in glob.glob(\"../Data/{}_rep_viruses/*.gff\".format(host_id)):\n",
    "        fasta_file = gff_file.replace(\".gff\", \".fasta\")\n",
    "        tsv_file = gff_file.replace(\".gff\", \".tsv\")\n",
    "\n",
    "        viral_df, viral_genome = gff3_parsing.compile_sequences([gff_file], [fasta_file], upstream_len)\n",
    "        viral_df = analyze_genome(viral_df, energy_dict)\n",
    "        viral_df.to_csv(tsv_file, sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
